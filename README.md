# 서울특별시 구별 시간대별 배달주문정도 예측 모델 개발
머신러닝 관련 프로젝트에서 Logistic Regression, Random Forest, XGBoost, LGBM 모델을 사용하여 서울특별시의 구별, 시간대별로 배달 주문의 정도(많음, 보통, 적음)을 예측하는 모델을 개발했다.

## 프로젝트 개요 및 필요성
코로나 19가 시작되고 사람들의 야외활동이 자제되면서 여러 시장들이 침체가 되었을텐데 온라인 배달시장과 라이더 일자리 만큼은 규모가 해마다 증가하고 있는 추세이기 때문에 이 배달 데이터를 사용한 데이터분석이 현재 상황에서 유익하고 흥미로운 분석이 될 것 같아 배달 데이터를 선정하게 되었다.

배달 과정에서 금전적인 이익이 발생하는 라이더와, 매장 중 

- 라이더 입장에서는 어떤 시간대에 어떤 구가 주문이 많은지 파악할 수 있도록 한다.

- 매장의 입장에서는 어떤 시간대에 내 매장이 주문이 많은지를 파악할 수 있는 정보를 제공하고자 한다.

## 프로젝트에서 사용한 가설
1. 날씨 변수들은 주문 정도에 큰 영향을 미칠 것이다. 

2. 구별 인구수가 더 많은 구가 주문을 더 많이 시켰을 것이다. 

3. 축구 경기가 있는 날이면 사람들이 치킨을 더 많이 시킬 것이다.

## 프로젝트 파이프라인
1. Beautiful soap 라이브러리를 사용하여 기상청에서는 서울시 구별, 시간대별 날씨 데이터를, 네이버에서는 축구 경기 데이터를, 서울 열린데이터 광장에서는 구별 인구수 데이터와 미세먼지 데이터를 크롤링했고, KT Big Data Platform에서 제공한 원본 데이터와 병합했다.

2. 병합한 데이터를 csv 형태로 저장하고, Logistic Regression, XGBoost, Random Forest, LGBM 모델을 만들어서 성능을 비교했다.

3. 모델링에 사용한 데이터를 지도로 시각화 하면서 인사이트를 도출했다.

![image](https://user-images.githubusercontent.com/97672187/178413355-42ea29c0-a392-48c8-9da1-b4734bd6aa90.png)

## 데이터 설명 및 전처리
- 설명

데이터는 KT 빅데이터 플랫폼에서 제공하는 전국 구별, 시간대별 주문건수 데이터를 사용했고 570만개의 행, 6개의 열로 이루어져있다. 결측치와 중복으로 표현된 데이터는 존재하지 않았다.

![image](https://user-images.githubusercontent.com/97672187/178460336-381fc0fd-f90c-49bd-a27b-decd2446c8b2.png)

위의 그래프 중 왼쪽 그래프는 도별로, 오른쪽 그래프는 시별로 주문건수를 파이 차트로 나타낸 것입니다. 서울 특별시는 도 단위에서는 경기도 다음으로 시 단위에서는 의정부시 다음으로 주문건수가 많았습니다. 주문건수가 가장 많은 도시를 분석에 사용하는 것이 좋겠지만, 서울특별시는 다른 시도와는 달리 밑에 보이는 테이블처럼 데이터가 구별로 세분화되어 있기 때문에 더 세밀한 분석을 위해 분석할 도시로 선정했다.

![image](https://user-images.githubusercontent.com/97672187/178460884-6b461152-db19-4641-9703-175cf409f89c.png)

- 전처리

타겟변수로는 어떤 시간대에 어떤 구의 주문건수가 5건이야, 10건이야 라고 예측하는 것보다, 주문이 많을 거야, 적을거야 라고 예측하는 것이 비교할 때 더 좋은 방법이 될 것 같아서 주문건수가 아닌 주문 정도를 사용했다. 주문 정도는 주문건수를 적절한 비율로 나눠서 해당 시간대에 주문건수가 2이하면 1, 3이상 4이하면 2, 5이상이면 3으로 정도를 나눴다. 

또한, 이 주문건수로 타겟인 주문 정도를 만들었기 때문에 Data leakage를 해소하기 위해 주문건수 변수는 제거했다. 

날씨, 미세먼지, 구별 인구수, 축구 데이터를 크롤링하고 요일, 주말, 공휴일 등의 변수를 기존데이터에 추가한 최종 데이터 형태는 72만개의 행, 30개의 열로 이루어져있다.

![image](https://user-images.githubusercontent.com/97672187/178461826-593955a5-ebcd-4fb3-b0ce-9c736b1e0465.png)

## 모델링
예측결과는 연속적인 수치가 아니라 많음, 보통, 적음이라는 대소 관계로 표현되는 주문의 정도이기 때문에 다중분류회귀모델을 사용했고, 정답을 오답에 비해 정답이라고 잘 예측하는지 평가하기 위해 평가지표로는 Accuracy외에도 AUC를 사용했다.

1) 최빈값을 사용한 기준 모델의 정확도는 49퍼센트, Logistic회귀를 사용한 정확도는 58퍼센트였다. Logistic 회귀에서는 AUC가 0.71이 나왔고, 이 수치보다 더 높은 수치를 내는 모델을 만드는 것을 목표로 모델링을 진행했다.

2) 2차 모델링에서는 모든 변수를 사용했고, 로지스틱 회귀보다는 조금 더 복잡한 트리기반 모델인 랜덤포레스트, XGBoost, LGBM을 사용했다. 그 결과 랜덤포레스트에서는 과적합이 발생했고, 하이퍼 파라미터 튜닝 없이도 과적합이 발생하지 않고, 정확도와 AUC가 어느 정도 보장되는 XGBoost와 LGBM 모델을 최적화 시키기로 했다.

3) 3차 모델링에서는 Randomized Search CV를 통해 최적화를 진행했다. 그 결과, XGBoost는 2차 모델링에 비해 성능이 조금 올라갔지만, 과적합이 생겼고, LGBM은 검증 AUC 외에는 모든 지표의 성능이 오히려 떨어졌다. 아마 모든 변수를 다 사용했기 때문에 불필요한 변수가 성능에 안 좋은 영향을 미친 것 같다.

![image](https://user-images.githubusercontent.com/97672187/178463258-67b62228-55e8-4b4c-a080-7582cb48480c.png)

4) 4차 모델링에서는 변수 중요도가 상대적으로 낮은 축구, 미세먼지, 풍속 등의 불필요한 변수를 제거하고 수동으로 파라미터들을 튜닝했다. XGBoost와 LGBM에서 각각 다른 변수들을 사용했고, 최종적으로는 LGBM이 성능이 가장 좋았다. 검증 정확도와 AUC가 각각 0.7271과 0.8727이 나오면서, 초기에 모델링 했던 로지스틱 회귀의 0.5866 정확도, 0.71의 AUC보다 훨씬 좋은 성능을 기록했다. 

## 결론

![image](https://user-images.githubusercontent.com/97672187/178464100-10fb0200-8bec-4de6-b7a3-ae7abe994764.png)

- 모델 해석

위의 그래프는 LGBM의 Shap와 변수 중요도를 나타낸 그래프이다. Shap에서는 시간 변수가 타겟에 가장 많은 영향을 미쳤습니다. 주문하는 시간대가 저녁, 야식처럼 피크 타임이냐 아니냐에 따라 주문 정도가 많이 차이날 것 같다. 변수 중요도에서는 기온이 시간변수 다음으로 성능에 가장 많은 영향을 미쳤다. 날씨에 따라서 사람들이 먹고 싶은 음식이나, 집에 머물러 있는 정도가 다르기 때문에 이러한 점이 영향을 미친 것 같다.

- 가설 검증
1. 날씨 변수들은 주문 정도에 큰 영향을 미칠 것이다. 

-> 전처리 과정에서 기온 외에 일강수량, 미세먼지 등 여러 날씨 변수를 추가해서 모델링에 사용했는데 성능이 오히려 떨어졌다. 따라서 기온을 제외한 날씨 변수는 주문정도에 큰 영향을 미치지 않는다라고 할 수 있다.

2. 구별 인구수가 더 많은 구가 주문을 더 많이 시켰을 것이다. 

![image](https://user-images.githubusercontent.com/97672187/178464788-acbe3489-9508-4b48-aaac-a2fc9edc5875.png)

-> 왼쪽은 구별 인구수를 나타내는 지도고 오른쪽은 주문량을 나타낸 지도이다. 색이 붉은색으로 진할수록 정도가 큰 것인데 두 지도의 분포가 확연히 다른 것을 확인할 수 있다. 송파구와 강서구가 인구가 많은 반면 주문량은 많지 않았고, 오히려 인구가 별로 많지 않은 구로구의 주문량이 젤 많았다. 따라서, 인구가 많다고 꼭 주문량이 많은 것은 아닌 것을 알 수 있다.

3. 축구 경기가 있는 날이면 사람들이 치킨을 더 많이 시킬 것이다.

![image](https://user-images.githubusercontent.com/97672187/178465075-526f9942-a90f-41a2-a35c-9c0214465352.png)

-> 축구 경기가 있는 날이 축구 경기가 없는 날에 비해 주문 많음의 비율이 11퍼센트 이상 더 큰 것을 보아 사람들이 축구 경기가 없을 때보다 있을 때, 치킨을 더 많이 시킨다는 것을 확인할 수 있다.


## 한계점 및 해결방안
1) 데이터가 동별로 되어 있지 않아 더 세밀한 분석이 어려웠다. 

-> 동별로 세분화된 데이터가 제공된다면 동별 시간대별 주문 정도를 예측하거나, 주문 건수를 예측하여 보다 해당 지역에 특화된 인사이트를 제공해줄 수 있을 것이다.

2) 기온 변수가 없었다면 중복되는 데이터가 많이 생겼을텐데 이것은 곧 수치형 변수가 부족해서 더 다양한 튜닝을 하는 것이 어려웠다고 해석할 수 있다.

-> 날씨 데이터가 예상과는 달리 주문 정도에 큰 영향을 미치지 않으면서 모델링 과정에서 제거했었다. 범주형 변수를 피처 엔지니어링 하는 기술을 보완하거나 구별, 업종별로
매장이 얼마나 있는지 등의 변수가 제공되어 있었다면 더 다양한 튜닝을 시도해보았을 것이다.

3) Randomized Search CV를 사용했을 때 걸린 시간에 비해 좋지 못한 성능이 나와서 수동으로 최적화를 해야했다.

-> 짧은 프로젝트 기간의 특성상 모델을 학습하고 튜닝하는데 많은 시간을 들이지 못했다. 시간이 좀 더 주어진다면 더 높은 정확도와 AUC를 가지는 모델을 개발할 수 있을 것이다. 

## 개발환경

![image](https://user-images.githubusercontent.com/97672187/178467020-04eb044d-7ad1-4bcf-acf1-135c1a57df7a.png)

